{
  "models": {
    "small": {
      "vocab_size": 32016,
      "hidden_size": 256,
      "num_layers": 4,
      "num_heads": 4,
      "max_position_embeddings": 2048,
      "dropout": 0.1,
      "attention_dropout": 0.1,
      "layer_norm_eps": 1e-5,
      "initializer_range": 0.02
    },
    "medium": {
      "vocab_size": 32016,
      "hidden_size": 768,
      "num_layers": 13,
      "num_heads": 12,
      "max_position_embeddings": 2048,
      "dropout": 0.1,
      "attention_dropout": 0.1,
      "layer_norm_eps": 1e-5,
      "initializer_range": 0.02
    },
    "large": {
      "vocab_size": 32016,
      "hidden_size": 1536,
      "num_layers": 40,
      "num_heads": 24,
      "max_position_embeddings": 2048,
      "dropout": 0.1,
      "attention_dropout": 0.1,
      "layer_norm_eps": 1e-5,
      "initializer_range": 0.02
    }
  },
  
  "default_model_size": "medium",
  
  "rope": {
    "theta": 10000.0,
    "scaling_type": "linear",
    "scaling_factor": 1.0
  },
  
  "tokenizer": {
    "bos_token_id": 1,
    "eos_token_id": 2,
    "unk_token_id": 0,
    "pad_token_id": 2
  },
  
  "training": {
    "batch_size": 8,
    "gradient_accumulation_steps": 64,
    "num_epochs": 1,
    "learning_rate": 0.0006,
    "min_learning_rate": 0.0001,
    "warmup_ratio": 0.02,
    "cosine_target_ratio": 0.8,
    "weight_decay": 0.1,
    "max_grad_norm": 1.0,
    "num_data_subsets": 64
  },
  
  "logging": {
    "eval_steps": 500,
    "save_steps": 1000,
    "logging_steps": 10
  },
  
  "dataset": {
    "source": "fineweb",
    "fineweb_raw_dir": "/home/andrea/Desktop/data/raw/fineweb",
    "fineweb_test_dir": "/home/andrea/Desktop/data/tokenized_datasets/fineweb_test_dataset",
    "fineweb_full_dir": "/home/andrea/Desktop/data/tokenized_datasets/fineweb_full_dataset"
  },
  
  "paths": {
    "checkpoint_dir": "checkpoints",
    "log_dir": "logs",
    "tokenizer_dir": "tokenizers/codellama_tokenizer",
    "raw_data_dir": "/home/andrea/Desktop/data/raw",
    "dataset_dir": "/home/andrea/Desktop/data/tokenized_datasets/fineweb_full_dataset"
  },
  
  "pytorch_backend": {
    "allow_tf32": true,
    "matmul_precision": "high"
  },
  
  "architecture_features": {
    "tie_embeddings": true
  }
}
